{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd372f5-c776-4b62-b6db-5eb566d43783",
   "metadata": {},
   "source": [
    "# Numerisk derivasjon\n",
    "\n",
    "Dersom vi vet den nøyaktige formen til en funksjon $f = f(x)$, kan vi bruke regnereglene vi kjenner til å derivere den.\n",
    "I praksis kjenner vi ikke alltid formen til funksjonen vi vil studere, men har bare delvis informasjon om denne gjennom målinger, osv.\n",
    "For eksempel kan det hende at vi bare kjenner til verdien av $f$ i en gitt liste av $x$-verdier.\n",
    "I slike tilfeller kan vi finne tilnærminger av den deriverte ved hjelp av numerisk derivasjon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00d80a3-5376-45fd-a9b4-36eed572250d",
   "metadata": {},
   "source": [
    "### Sekanter, stigningstall og den deriverte\n",
    "\n",
    "La oss se på en skalar funksjon $f = f(x)$ av én skalar variabel $x$.\n",
    "Den deriverte av funksjonen $f$ i et punkt $x=a$ uttrykker endringsraten til funksjonen $f$ med hensyn på den frie variabelen $x$:\n",
    "altså hvor mye funksjonen\n",
    "\n",
    "I punktet $x=a$ tar funksjonen verdien $f(a)$.\n",
    "Dersom vi går et steg $h > 0$ fremover langs $x$-aksen befinner vi oss i punktet $x = a+h$, hvor funksjonen tar verdien $f(a+h)$.\n",
    "På dette steget har altså funksjonsverdien endret seg med differansen $f(a+h)-f(a)$, og dersom vi deler dette på hvor mye $x$ har endret seg, altså $(a+h)-a=h$, får vi følgende forholdstall,\n",
    "\n",
    "$$ \\frac{f(a+h)-f(a)}{h}. $$\n",
    "\n",
    "Den rette linjen som går gjennom punktene $(a,f(a))$ og $(a+h,f(a+h))$ kalles en *sekant*, eller sekantlinje, og denne har stigningstall gitt nøyaktig av brøken ovenfor.\n",
    "La oss illustrere dette i en figur, hvor vi har tegnet inn grafen til en funksjon $y=f(x)$ og sekanten som går gjennom to slike punkter.\n",
    "\n",
    "<img src=\"1_sekant.png\" style=\"width: 60%\">\n",
    "I figuren ovenfor har vi også tegnet inn tangentlinjen til grafen i punktet $x=a$; dette er den rette linjen som går gjennom punktet $(a,f(a))$ med samme stigningstall som endringsraten til $f$ i punktet $a$.\n",
    "Basert på figuren kan vi ser for oss hvordan sekantlinjen vil nærme seg tangentlinjen dersom vi tar stadig kortere steg $h$.\n",
    "\n",
    "Dette gjenspeiles i [definisjonen](../A_appendiks/A_derivasjon.ipynb) av den deriverte $f'$ i punktet $x=a$, som er gitt av *grenseverdien*\n",
    "\n",
    "$$ f'(a) \\doteq \\lim_\\limits{h\\to0}\\frac{f(a+h)-f(a)}{h}. $$\n",
    "\n",
    "Vi går ikke inn på den nøyaktige definisjonen av en grenseverdi her, men i vårt tilfelle kan vi godt tenke på det som verdien dette forholdstallet (stigningstallet til sekanten) går mot når vi velger $h$ stadig nærmere null.\n",
    "Dersom en slik verdi eksisterer, sier vi at $f$ er deriverbar i punktet $x=a$ og den deriverte $f'(a)$ er lik denne verdien.\n",
    "Da er kan vi for eksempel uttrykke grafen til tangentlinjen i dette punktet som\n",
    "\n",
    "$$ y = f(a) + f'(a)(x-a). $$\n",
    "\n",
    ">**Merk:** Å la $h$ gå mot null som i definisjonen av den deriverte er *ikke* det samme som å sette inn for $h=0$ i forholdstallet; da ville vi fått $\\frac00$, som ikke gir mening.\n",
    "Siden vi i denne prosedyren må velge skrittlengden $h$ stadig nærmere null, men aldri sette den nøyaktig lik null, må vi på et vis gjennom \"uendelig mange steg\" for å få grenseverdien.\n",
    "I en numerisk beregning med en datamaskin vil vi derimot bare være i stand til å utføre endelig mange operasjoner.\n",
    "En måte å få en tilnærming av $f'(x)$ kan da være å ta en (veldig) liten verdi for $h$ og bruke det tilhørende forholdstallet: dette er idéen bak (endelige) differansemetoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ca4f0-88cb-40e4-ad40-744986f2248b",
   "metadata": {},
   "source": [
    "## Differansemetoder\n",
    "\n",
    "Basert på idéen ovenfor har vi det som kalles *differansemetoder* for å tilnærme deriverte av en funksjon $f$ i punktet $x$.\n",
    "For $h > 0$ kan vi definere *foroverdifferansen* i punktet $x$,\n",
    "\n",
    "$$ \\frac{f(x+h)-f(x)}{h}, \\tag{1.1} $$\n",
    "\n",
    "som vi gjenkjenner som stigningstallet til sekanten gjennom punktene $(x,f(x))$ og $(x+h,f(x+h))$.\n",
    "På lignende vis kan vi for $h>0$ definere *bakoverdifferansen*\n",
    "\n",
    "$$ \\frac{f(x)-f(x-h)}{h}, \\tag{1.2} $$\n",
    "\n",
    "som egentlig bare tilsvarer uttrykket (1.1) med en negativ skrittlengde $h = -|h|$.\n",
    "\n",
    "Vi kan også ta gjennomsnittet av dem, $\\frac12$ ganger (1.1) pluss $\\frac12$ ganger (1.2), og få det som kalles *senterdifferansen*\n",
    "\n",
    "$$ \\frac{f(x+h)-f(x-h)}{2h}. \\tag{1.3} $$\n",
    "\n",
    "La oss illustrere disse visuelt gjennom et eksempel.\n",
    "\n",
    ">#### Eksempel:\n",
    "La oss se på funksjonen $f(x) = e^x$ og se hvordan differansene ovenfor fungerer som tilnærminger av den deriverte $f'(x) = e^x$ i punktet $x=0$.\n",
    "Her er den deriverte $f'(0) = e^0 = 1$, så dette er stigningstallet til tangenten til kurven $y = e^x$ i dette punktet.\n",
    "Denne tangenten er gitt av den blå punkt-stiplede linjen i figurene nedenfor.\n",
    "Stigningstallet til den røde stiplede linjen tilsvarer verdien til differansene; foroverdifferanse (a), bakoverdifferanse (b) og senterdifferanse (c).\n",
    "Desto nærmere denne er å være parallell med den blå tangentlinjen, desto bedre er tilnærmingen av den deriverte.\n",
    ">\n",
    "><img src=\"1_differences_illustration.png\" style=\"width: 60%\">\n",
    ">\n",
    ">I dette tilfellet ser vi fra figurene at senterdifferansen gir den beste tilnærmingen, linjene er nærmest å være parallelle her.\n",
    "Men i alle tilfellene ser vi at når vi lar skrittlengden $h>0$ gå mot null, vil de røde linjene nærme seg tangentlinjen.\n",
    "\n",
    "I det neste eksempelet skal vi se noen tallverdier for disse differansene.\n",
    "\n",
    ">#### Eksempel:\n",
    "La oss se på funksjonen $f(x) = x^3$ og bruke differanser med steglengde $h=0.1$ til å tilnærme den deriverte i punktet $x=1$, hvor den eksakte deriverte er $f'(1) = 3$.\n",
    "Vi setter inn for i uttrykket (1.1) for foroverdifferansen og finner\n",
    ">\n",
    ">$$ \\frac{f(1+0.1)-f(1)}{0.1} = \\frac{(1.1)^3-1^3}{0.1} = \\frac{0.331}{0.1} = 3.31. $$\n",
    ">\n",
    ">Dermed gir foroverdifferansen et avvik på $0.31$.\n",
    "Tilsvarende finner vi for bakover- og senterdifferansen (1.2) og (1.3) at\n",
    ">\n",
    ">$$ \\frac{1^3-(0.9)^3}{0.1} = \\frac{0.271}{0.1} = 2.71, \\qquad \\text{og} \\qquad \\frac{(1.1)^3-(0.9)^3}{0.2} = \\frac{0.602}{0.2} = 3.01. $$ \n",
    ">\n",
    ">Altså gir bakoverdifferansen avviket $0.29$, og senterdifferansen gir et avvik på kun $0.01$.\n",
    "\n",
    "I dette eksempelet ser vi at senterdifferansen gav en bedre tilnærming enn de andre differansene. Dette vil typisk være tilfellet for funksjoner som er \"veloppdragne\", i den forstand at de er kontinuerlige og kan deriveres så mange ganger vi ønsker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6cfe4-5909-48d8-9601-d073cf33e270",
   "metadata": {},
   "source": [
    "## Avvik\n",
    "Man kan vise at for en tilstrekkelig glatt funksjon $f$ vil feilen $|f'(x)-\\Delta_h f(x)|$ vi gjør ved å tilnærme $f'(x)$ med en av disse differansene, som vi her kaller $\\Delta_h f(x)$, avta lineært med skrittlengden $h$ for forover- og bakoverdifferanser, og kvadratisk med skrittlengden $h$ for senterdifferansen.\n",
    "Hva dette betyr skal vi se nedenfor.\n",
    "\n",
    "For forover- og bakoverdifferanser har kan vi utlede formlene\n",
    "$$\\left|\\pm\\frac{f(x\\pm h)-f(x)}{h} - f'(x)\\right| = \\frac{h}{2}|f''(c)| \\quad \\text{for en } c \\text{ mellom } x \\text{ og } x\\pm h, \\tag{1.4} $$\n",
    "og for sentraldifferansen har vi\n",
    "$$ \\left| \\frac{f(x+h)-f(x-h)}{2h} - f'(x) \\right| = \\frac{h^2}{6} |f'''(c)| \\quad \\text{for en } c \\text{ slik at } x-h < c < x+h. \\tag{1.5} $$\n",
    "\n",
    "Her ser vi at avviket (1.4) ved bruk av forover- og bakoverdifferanser er lineært i $h$. Dette betyr for eksempel at dersom vi halverer skrittlengden $h$, altså $h_\\text{ny} = \\frac12 h_\\text{gammel}$, så forventer vi at også avviket halveres sammenlignet med hva det var.\n",
    "\n",
    "På den andre siden er avviket (1.5) ved bruk av senterdifferanse kvadratisk i $h$, fordi $h$ her er opphøyd i andre potens, $h^2$.\n",
    "Dermed, dersom vi halverer skrittlengden $h$, $h_\\text{ny} = \\frac12 h_\\text{gammel}$, så forventer vi at det nye avviket er en fjerdedel av det gamle, fordi $(h_\\text{ny})^2 = (\\frac12 h_\\text{gammel})^2 = \\frac14 (h_\\text{gammel})^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695f32d-6c0a-4dd4-b866-d5b15f0c1fe1",
   "metadata": {},
   "source": [
    "> #### Eksempel:\n",
    "La oss sjekke om resultatene vi fikk i forrige eksempel stemmer overens med uttrykkene (1.4) og (1.5).\n",
    "Siden vi ikke vet nøyaktig hva verdien av $c$ er i disse formlene, er det beste vi kan gjøre å finne en øvre grense for hvor store $|f''(c)|$ og $|f'''(c)|$ kan bli, slik at vi kan sjekke at svarene våre ligger innenfor denne grensen.\n",
    ">\n",
    ">Den andrederiverte av funksjonen $f$ er $f''(x) = 6x$.\n",
    "På intervallet $[1,1.1]$ er $|f''(1.1)| = 6.6$ den største absoluttverdien denne kan ha, og dermed kan avviket ved bruk af foroverdifferanse umulig bli større enn $\\frac{0.1}{2}\\cdot 6.6 = 0.33$. Dette stemmer med at vi fikk avviket $0.31$.\n",
    ">\n",
    ">På intervallet $[0.9,1]$ er derimot $|f''(1)| = 6$ den største absoluttverdien $f''$ kan ta, slik at avviket med bakoverdifferanse maksimalt kan bli $\\frac{0.1}{2}\\cdot 6 = 0.3$. Igjen, dette stemmer med at vi fikk avviket $0.29$.\n",
    ">\n",
    ">Generelt ville man her ha funnet den største absoluttverdien som den tredjederiverte av $f$ kan ha på intervallet $[0.9,1.1]$, men her er en tredjederiverte er en konstant, $f'''(x) = 6$, så for denne funksjonen ser vi at avviket ved bruk av senterdifferanse alltid er gitt av $\\frac{h^2}{6}\\cdot 6 = h^2$.\n",
    "For $h = 0.1$ er dette nøyaktig avviket $0.01$ som vi fikk.\n",
    "\n",
    "> #### Eksempel:\n",
    "Dersom $f$ er en lineær funksjon, det vil si $f(x) = ax + b$ for to konstanter $a$ og $b$, ser vi at alle disse differansene gir oss samme verdi $a$, uavhengig av steglengden $h$.\n",
    "Dette er den eksakte verdien for den deriverte, så her er avviket null mellom eksakt verdi og tilnærmingene gitt av differansene. Stemmer med uttrykkene over, både $f''$ og $f'''$ er identisk lik null.\n",
    ">\n",
    ">Ser du hvilken annen type funksjoner som senterdifferansen vil gi et eksakt svar for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defc424-f6fd-4b54-9250-5ed85406bcc4",
   "metadata": {},
   "source": [
    "I det neste eksempelet vil vi forsøke å illustrere effekten av at avviket for forover- og bakoverdifferanser er proporsjonalt med $h$, imens avviket for senterdifferansen er proporsjonalt med $h^2$.\n",
    "\n",
    "> #### Eksempel:\n",
    "La oss se på funksjonen $f(x) = e^{x}$.\n",
    "Den deriverte er funksjonen selv, $f'(x) = e^x$, og vi ser på differansene i punktet $x = 0$ for skrittlengder $h = 1/n$, hvor $n = 1,\\dots,20$.\n",
    "<img src=\"1_differanser.png\" style=\"width: 100%\">\n",
    "Det venstre plottet viser verdien av differansene for ulike skrittlengder, sammenlignet med verdien av den deriverte $f'(0) = e^0 = 1$.\n",
    "Merk at siden $f'' > 0$ for denne funksjonen er den deriverte $f'$ også økende.\n",
    "Dermed vil foroverdifferansen konsekvent overestimere $f'(x)$, imens bakoverdifferansen vil konsekvent underestimere, og dette ser vi i det midterste plottet.\n",
    "Da er det rimelig at sentraldifferansen, som kan betraktes som et gjennomsnitt av de foregående differansene, gir en bedre tilnærming.\n",
    ">\n",
    ">Feilen er plottet til høyre, hvor vi ser at feilen med forover- og bakoverdifferanser er omtrent den samme, og avtar med samme stigningstall som $h$.\n",
    "Videre ser vi at feilen med senterdifferanser avtar raskere, som en kvadratisk funksjon av $h$.\n",
    "\n",
    ">**Logaritmisk skalering av aksene:**\n",
    "Vi ser at $h = 1/n$ blir veldig liten for større verdier av $n$, og det kan være vanskelig å skille punktene i et plott fra hverandre; da kan det være til hjelp å skalere aksene i plottet annerledes.\n",
    "I det midterste plottet skalerer vi (på vanlig vis) $y$-aksen lineært, men $x$-aksen logaritmisk; det vil si, når vi går én enhet langs $y$-aksen går vi fra $y=k$ til $y=k+1$, men langs $x$-aksen går vi i stedet fra $x = 10^{k}$ til $x = 10^{k+1}$.\n",
    "I det høyre plottet av feilen blir både $x$- og $y$-verdiene veldig små, så vi skalerer begge aksene logaritmisk.\n",
    "I disse figurene har vi brukt henholdsvis kommandoene `pyplot.semilogx()` og `pyplot.loglog` istedenfor `pyplot.plot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fbfd1-2a39-4b27-ac1e-6be06bc32793",
   "metadata": {},
   "source": [
    "### Implementasjon\n",
    "\n",
    "Differansene ovenfor egner seg utmerket for å la datamaskiner ta seg av beregningene.\n",
    "\n",
    "Si at vi vil beregne foroverdifferansen av $f(x) = \\sin(x)$ i en rekke punkter; i dette tilfellet $x_n = n h$ for $h = 0.1$ og $n = 0,\\dots,9$.\n",
    "Da kan vi implementere dette i Python som en for-løkke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b44731-06f2-422f-a92f-d84c75069057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99833417 0.98835914 0.96850876 0.93898136 0.90007196 0.85216935\n",
      " 0.79575214 0.73138404 0.65970819 0.58144075]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # importer numpy-biblioteket\n",
    "\n",
    "h = 0.1 # steglengde\n",
    "\n",
    "df1 = np.zeros(10) # liste for å lagre de 10 differansene\n",
    "\n",
    "for n in range(0,10):\n",
    "    df1[n] = (np.sin((n+1)*h)-np.sin(n*h))/h\n",
    "     \n",
    "print(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79ccd7-d8ea-45dc-af5e-ec13f1cf0da0",
   "metadata": {},
   "source": [
    "Siden numerisk derivasjon er et såpass vanlig bruksområde finnes det også en hel rekke innebygde funksjoner som kan være nyttige i denne sammenhengen.\n",
    "\n",
    "`numpy.linspace(a,b,n)` som gir et array med $n \\ge 2$ jevnt fordelte tall mellom $a$ og $b$, inkludert endepunktene selv.\n",
    "Dersom man setter argumentet `retstep=True` vil den også gi ut differansen mellom hvert tall.\n",
    "\n",
    "`numpy.diff()` som tar inn et array av $n+1$ verdier, la oss si $[x_0,x_1,\\dots,x_n]$, og returnerer et array med de $n$ differansene av disse verdiene, i dette tilfellet $[x_1-x_0, x_2-x_1, \\dots, x_n-x_{n-1}]$.\n",
    "\n",
    "Nedenfor bruker vi disse istedenfor til å beregne differansene som vi i stad brukte en for-løkke til.\n",
    "\n",
    "Vi kan også sammenligne med verdien av $\\cos(x) = (\\sin(x))'$ i disse punktene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ade29c08-a3a1-4e16-a3c0-3fac55169837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99833417 0.98835914 0.96850876 0.93898136 0.90007196 0.85216935\n",
      " 0.79575214 0.73138404 0.65970819 0.58144075]\n",
      "[1.         0.99500417 0.98006658 0.95533649 0.92106099 0.87758256\n",
      " 0.82533561 0.76484219 0.69670671 0.62160997]\n"
     ]
    }
   ],
   "source": [
    "x, h = np.linspace(0,1,11,retstep=True) # array x med 11 jevnt fordelte verdier mellom 0 og 1, h \n",
    "\n",
    "f = np.sin(x) # sin() evaluert i punktene\n",
    "\n",
    "df2 = np.diff(f)/h # beregn foroverdifferansene i punktene x[:-1] (alle utenom det siste)\n",
    "\n",
    "print(df2)\n",
    "\n",
    "print(np.cos(x[:-1])) # sammenlign med den deriverte av sin(x), cos(x), i de samme punktene (alle utenom det siste)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8a67b-2015-47c1-9696-2650449ba85a",
   "metadata": {},
   "source": [
    "> $\\impliedby$ [Innholdsfortegnelse](../0_innholdsfortegnelse.ipynb) | [Numerisk derivasjon: ustabilitet](1_diffint_ustabilitet.ipynb) $\\implies$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee59d6a1-19fd-41e7-913e-47ab8135c07b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd372f5-c776-4b62-b6db-5eb566d43783",
   "metadata": {},
   "source": [
    "# Numerisk derivasjon\n",
    "\n",
    "Dersom vi vet den nøyaktige formen til en funksjon $f = f(x)$, kan vi bruke regnereglene vi kjenner til å derivere den.\n",
    "I praksis kjenner vi ikke alltid formen til funksjonen vi vil studere, men har bare delvis informasjon om denne gjennom målinger, osv.\n",
    "For eksempel kan det hende at vi bare kjenner til verdien av $f$ i en gitt liste av $x$-verdier.\n",
    "I slike tilfeller kan vi finne tilnærminger av den deriverte ved hjelp av numerisk derivasjon."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ca4f0-88cb-40e4-ad40-744986f2248b",
   "metadata": {},
   "source": [
    "## Differansemetoder\n",
    "For en skalar funksjon $f = f(x)$ av én variabel husker vi at [definisjonen](A_derivasjon.ipynb) av den deriverte $f'$ i punktet $x$ er\n",
    "\n",
    "$$ f'(x) \\doteq \\lim_\\limits{h\\to0}\\frac{f(x+h)-f(x)}{h}. $$\n",
    "\n",
    "Dersom denne grensen eksisterer kan vi for eksempel ta $h = 1/n$ for $n = 1, 2, 3,\\dots$, og definere\n",
    "\n",
    "$$ g_n \\doteq n\\left( f(x+1/n) - f(x) \\right) \\ \\substack{n \\to \\infty \\\\ \\longrightarrow} \\ f'(x).$$\n",
    "\n",
    "Merk at i denne prosedyren må vi gjennom \"uendelig mange steg\" for å få grenseverdien, nettopp fordi vi må la $n \\to \\infty$.\n",
    "I en numerisk beregning med en datamaskin vil vi derimot bare være i stand til å utføre endelig mange operasjoner.\n",
    "En måte å få en tilnærming av $f'(x)$ kan da være å ta en stor verdi for $n$ og velge den tilhørende $g_n$.\n",
    "\n",
    "Basert på idéen ovenfor har vi det som kalles *endelige differansemetoder* for å tilnærme deriverte av en funksjon $f$ i punktet $x$.\n",
    "For $h > 0$ kan vi definere en *foroverdifferanse*\n",
    "\n",
    "$$ \\frac{f(x+h)-f(x)}{h}, \\tag{1.1} $$\n",
    "\n",
    "og en *bakoverdifferanse*\n",
    "\n",
    "$$ \\frac{f(x)-f(x-h)}{h}. \\tag{1.2} $$\n",
    "\n",
    "Vi kan også ta gjennomsnittet av dem og få det som kalles *senterdifferanse*,\n",
    "\n",
    "$$ \\frac{f(x+h)-f(x-h)}{2h}. \\tag{1.3} $$\n",
    "\n",
    ">#### Eksempel:\n",
    "La oss se på funksjonen $f(x) = x^3$ og bruke differanser med steglengde $h=0.1$ til å tilnærme den deriverte i punktet $x=1$, hvor den eksakte deriverte er $f'(1) = 3$.\n",
    "Vi setter inn for i uttrykket (1.1) for foroverdifferansen og finner\n",
    ">\n",
    ">$$ \\frac{f(1+0.1)-f(1)}{0.1} = \\frac{(1.1)^3-1^3}{0.1} = \\frac{0.331}{0.1} = 3.31. $$\n",
    ">\n",
    ">Dermed gir foroverdifferansen et avvik på $0.31$.\n",
    "Tilsvarende finner vi for bakover- og senterdifferansen (1.2) og (1.3) at\n",
    ">\n",
    ">$$ \\frac{1^3-(0.9)^3}{0.1} = \\frac{0.271}{0.1} = 2.71, \\qquad \\text{og} \\qquad \\frac{(1.1)^3-(0.9)^3}{0.2} = \\frac{0.602}{0.2} = 3.01. $$ \n",
    ">\n",
    ">Altså gir bakoverdifferansen avviket $0.29$, og senterdifferansen gir et avvik på kun $0.01$.\n",
    "\n",
    "I dette eksempelet ser vi at senterdifferansen gav en bedre tilnærming enn de andre differansene. Dette vil typisk være tilfellet for funksjoner som er \"veloppdragne\", i den forstand at de er kontinuerlige og kan deriveres så mange ganger vi ønsker."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b6cfe4-5909-48d8-9601-d073cf33e270",
   "metadata": {},
   "source": [
    "## Avvik\n",
    "Man kan vise at for en tilstrekkelig glatt funksjon $f$ vil feilen $|f'(x)-\\Delta_h f(x)|$ vi gjør ved å tilnærme $f'(x)$ med en av disse differansene, som vi her kaller $\\Delta_h f(x)$, avta lineært for forover- og bakoverdifferanser, og kvadratisk for sentraldifferansen.\n",
    "\n",
    "For forover- og bakoverdifferanser har kan vi utlede formlene\n",
    "$$\\left|\\pm\\frac{f(x\\pm h)-f(x)}{h} - f'(x)\\right| = \\frac{h}{2}|f''(c)| \\quad \\text{for en } c \\text{ mellom } x \\text{ og } x\\pm h, \\tag{1.4} $$\n",
    "og for sentraldifferansen har vi\n",
    "$$ \\left| \\frac{f(x+h)-f(x-h)}{2h} - f'(x) \\right| = \\frac{h^2}{6} |f'''(c)| \\quad \\text{for en } c \\text{ slik at } x-h < c < x+h. \\tag{1.5} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3695f32d-6c0a-4dd4-b866-d5b15f0c1fe1",
   "metadata": {},
   "source": [
    "> #### Eksempel:\n",
    "La oss sjekke om resultatene vi fikk i forrige eksempel stemmer overens med uttrykkene (1.4) og (1.5).\n",
    "Siden vi ikke vet nøyaktig hva verdien av $c$ er i disse formlene, er det beste vi kan gjøre å finne en øvre grense for hvor store $|f''(c)|$ og $|f'''(c)|$ kan bli, slik at vi kan sjekke at svarene våre ligger innenfor denne grensen.\n",
    ">\n",
    ">Den andrederiverte av funksjonen $f$ er $f''(x) = 6x$.\n",
    "På intervallet $[1,1.1]$ er $|f''(1.1)| = 6.6$ den største absoluttverdien denne kan ha, og dermed kan avviket ved bruk af foroverdifferanse umulig bli større enn $\\frac{0.1}{2}\\cdot 6.6 = 0.33$. Dette stemmer med at vi fikk avviket $0.31$.\n",
    ">\n",
    ">På intervallet $[0.9,1]$ er derimot $|f''(1)| = 6$ den største absoluttverdien $f''$ kan ta, slik at avviket med bakoverdifferanse maksimalt kan bli $\\frac{0.1}{2}\\cdot 6 = 0.3$. Igjen, dette stemmer med at vi fikk avviket $0.29$.\n",
    ">\n",
    ">Generelt ville man her ha funnet den største absoluttverdien som den tredjederiverte av $f$ kan ha på intervallet $[0.9,1.1]$, men her er en tredjederiverte er en konstant, $f'''(x) = 6$, så for denne funksjonen ser vi at avviket ved bruk av senterdifferanse alltid er gitt av $\\frac{h^2}{6}\\cdot 6 = h^2$.\n",
    "For $h = 0.1$ er dette nøyaktig avviket $0.01$ som vi fikk.\n",
    "\n",
    "> #### Eksempel:\n",
    "Dersom $f$ er en lineær funksjon, det vil si $f(x) = ax + b$ for to konstanter $a$ og $b$, ser vi at alle disse differansene gir oss samme verdi $a$, uavhengig av steglengden $h$.\n",
    "Dette er den eksakte verdien for den deriverte, så her er avviket null mellom eksakt verdi og tilnærmingene gitt av differansene. Stemmer med uttrykkene over, både $f''$ og $f'''$ er identisk lik null.\n",
    ">\n",
    ">Ser du hvilken annen type funksjoner som senterdifferansen vil gi et eksakt svar for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defc424-f6fd-4b54-9250-5ed85406bcc4",
   "metadata": {},
   "source": [
    "I det neste eksempelet vil vi forsøke å illustrere effekten av at avviket for forover- og bakoverdifferanser er proporsjonalt med $h$, imens avviket for senterdifferansen er proporsjonalt med $h^2$.\n",
    "\n",
    "> #### Eksempel:\n",
    "La oss se på funksjonen $f(x) = e^{x}$.\n",
    "Den deriverte er funksjonen selv, $f'(x) = e^x$, og vi ser på differansene i punktet $x = 0$ for skrittlengder $h = 1/n$, hvor $n = 1,\\dots,20$.\n",
    "<img src=\"1_differanser.png\" style=\"width: 100%\">\n",
    "Det venstre plottet viser verdien av differansene for ulike skrittlengder, sammenlignet med verdien av den deriverte $f'(0) = e^0 = 1$.\n",
    "Merk at siden $f'' > 0$ for denne funksjonen er den deriverte $f'$ også økende.\n",
    "Dermed vil foroverdifferansen konsekvent overestimere $f'(x)$, imens bakoverdifferansen vil konsekvent underestimere, og dette ser vi i det midterste plottet.\n",
    "Da er det rimelig at sentraldifferansen, som kan betraktes som et gjennomsnitt av de foregående differansene, gir en bedre tilnærming.\n",
    ">\n",
    ">Feilen er plottet til høyre, hvor vi ser at feilen med forover- og bakoverdifferanser er omtrent den samme, og avtar med samme stigningstall som $h$.\n",
    "Videre ser vi at feilen med sentraldifferanser avtar raskere, som en kvadratisk funksjon av $h$.\n",
    "\n",
    ">**Logaritmisk skalering av aksene:**\n",
    "Vi ser at $h = 1/n$ blir veldig liten for større verdier av $n$, og det kan være vanskelig å skille punktene i et plott fra hverandre; da kan det være til hjelp å skalere aksene i plottet annerledes.\n",
    "I det midterste plottet skalerer vi (på vanlig vis) $y$-aksen lineært, men $x$-aksen logaritmisk; det vil si, når vi går én enhet langs $y$-aksen går vi fra $y=k$ til $y=k+1$, men langs $x$-aksen går vi i stedet fra $x = 10^{k}$ til $x = 10^{k+1}$.\n",
    "I det høyre plottet av feilen blir både $x$- og $y$-verdiene veldig små, så vi skalerer begge aksene logaritmisk.\n",
    "I disse figurene har vi brukt henholdsvis kommandoene `pyplot.semilogx()` og `pyplot.loglog` istedenfor `pyplot.plot()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72fbfd1-2a39-4b27-ac1e-6be06bc32793",
   "metadata": {},
   "source": [
    "### Implementasjon\n",
    "\n",
    "Differansene ovenfor egner seg utmerket for å la datamaskiner ta seg av beregningene.\n",
    "\n",
    "Si at vi vil beregne foroverdifferansen av $f(x) = \\sin(x)$ i en rekke punkter; i dette tilfellet $x_n = n h$ for $h = 0.1$ og $n = 0,\\dots,9$.\n",
    "Da kan vi implementere dette i Python som en for-løkke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90b44731-06f2-422f-a92f-d84c75069057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99833417 0.98835914 0.96850876 0.93898136 0.90007196 0.85216935\n",
      " 0.79575214 0.73138404 0.65970819 0.58144075]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # importer numpy-biblioteket\n",
    "\n",
    "h = 0.1 # steglengde\n",
    "\n",
    "df1 = np.zeros(10) # liste for å lagre de 10 differansene\n",
    "\n",
    "for n in range(0,10):\n",
    "    df[n] = (np.sin((n+1)*h)-np.sin(n*h))/h\n",
    "     \n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d79ccd7-d8ea-45dc-af5e-ec13f1cf0da0",
   "metadata": {},
   "source": [
    "Siden numerisk derivasjon er et såpass vanlig bruksområde finnes det også en hel rekke innebygde funksjoner som kan være nyttige i denne sammenhengen.\n",
    "\n",
    "`numpy.linspace(a,b,n)` som gir et array med $n \\ge 2$ jevnt fordelte tall mellom $a$ og $b$, inkludert endepunktene selv.\n",
    "Dersom man setter argumentet `retstep=True` vil den også gi ut differansen mellom hvert tall.\n",
    "\n",
    "`numpy.diff()` som tar inn et array av $n+1$ verdier, la oss si $[x_0,x_1,\\dots,x_n]$, og returnerer et array med de $n$ differansene av disse verdiene, i dette tilfellet $[x_1-x_0, x_2-x_1, \\dots, x_n-x_{n-1}]$.\n",
    "\n",
    "Nedenfor bruker vi disse istedenfor til å beregne differansene som vi i stad brukte en for-løkke til.\n",
    "\n",
    "Vi kan også sammenligne med verdien av $\\cos(x) = (\\sin(x))'$ i disse punktene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ade29c08-a3a1-4e16-a3c0-3fac55169837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99833417 0.98835914 0.96850876 0.93898136 0.90007196 0.85216935\n",
      " 0.79575214 0.73138404 0.65970819 0.58144075]\n",
      "[1.         0.99500417 0.98006658 0.95533649 0.92106099 0.87758256\n",
      " 0.82533561 0.76484219 0.69670671 0.62160997 0.54030231]\n"
     ]
    }
   ],
   "source": [
    "x, h = np.linspace(0,1,11,retstep=True) # array x med 10 jevnt fordelte verdier mellom 0 og 1, h \n",
    "\n",
    "f = np.sin(x) # sin() evaluert i punktene\n",
    "\n",
    "df2 = np.diff(f)/h # beregn foroverdifferansene\n",
    "\n",
    "print(df2)\n",
    "\n",
    "print(np.cos(x)) # sammenlign med den deriverte av sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d623875a-c843-4b7d-86a9-ddddf73bc696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b630757-7493-4733-9a67-6eba7cd4e3db",
   "metadata": {},
   "source": [
    "# Konvergensrater for iterative metoder\n",
    "\n",
    "I forrige eksempel så vi at Newtons metode raskt gav stadig bedre tilnærminger av løsningen til $f(x)=0$.\n",
    "Her skal vi se hvordan vi kan sammenligne hvor hurtig tilnærmingene gitt av iterative metoder konvergerer mot løsningen.\n",
    "\n",
    ">#### Eksempel:\n",
    "La oss se hvordan Newtons metode sammenligner seg med fikspunktiterasjonen (med valget av $g$ som fungerte) i et tidligere eksempel, nemlig for $f(x) = x^3+x-1$ på intervallet $[0,1]$.\n",
    "Her ser vi at $f'(x) = 1 + 3x^2 \\ge 1$, så det er ingen fare for å dele på null.\n",
    ">\n",
    "><img src=\"2_fixVSnewton.png\" style=\"width: 100%\">\n",
    ">\n",
    ">Ovenfor har vi laget fikspunktplott for $g(x) = (1-x)^{1/3}$ og $g$ tilsvarende Newtons metode, i tillegg til et plott av $f$ og tangentlinjene tilhørende Newtons metode.\n",
    "Legg merke til hvor mye raskere Newtons metode tilnærmer roten $r$: andre og tredje iterat, dvs. $x_2$ og $x_3$, for Newtons metode ligger nærmest oppå hverandre i denne figuren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fad0584-7790-4a59-82bd-cbc38e6cf77f",
   "metadata": {},
   "source": [
    "En intuitiv forklaring på hvorfor Newtons metode raskere gir bedre tilnærminger enn en generisk fikspunktiterasjon er at den gjør seg bruk av mer informasjon om funksjonen $f$:\n",
    "I Newtons metode utnytter vi at vi kjenner den deriverte $f'$, og bruker denne til å finne hvor tangenten til grafen til $f(x)$ i $x=x_n$ skjærer $x$-aksen.\n",
    "\n",
    "For $f'(r)\\neq0$ vil feilen med Newtons metode avta kvadratisk, og ikke lineært som er typisk for fikspunktiterasjoner.\n",
    "\n",
    ">#### *Definisjon*:\n",
    "La $e_i$ være feilen etter $i$ steg med en iterativ metode. Dersom\n",
    "$$ \\lim\\limits_{i\\to\\infty} \\frac{e_{i+1}}{e_i} = S, \\quad \\text{hvor} \\quad 0 < S < 1, \\tag{3} $$\n",
    "sier vi at metoden er *lineært konvergent* med rate $S$.\n",
    "\n",
    "Dette betyr at for store nok verdier av $i$ vil neste feil $e_{i+1}$ være omtrent lik $S e_i$.\n",
    "\n",
    ">#### *Definisjon*:\n",
    "La $e_i$ være feilen etter $i$ steg med en iterativ metode. Vi sier at iterasjonen *konvergerer kvadratisk* dersom\n",
    "$$ \\lim\\limits_{i\\to\\infty} \\frac{e_{i+1}}{e_i^2} = M < \\infty.  $$\n",
    "\n",
    "Uttrykket ovenfor forteller oss at for store nok verdier av $i$ vil neste feil $e_{i+1}$ være omtrent lik $M e_i^2$.\n",
    "\n",
    "Feilen $e_i$ er gitt ved avviket $e_i = |x_i-r|$, hvor $r$ er roten vi er ute etter.\n",
    "Siden $r$ typisk er ukjent vil det være vanskelig å plotte denne feilen.\n",
    "Et godt alternativ kan da være å se på avviket mellom forrige og neste iterat, $|x_{i+1}-x_i|$.\n",
    "For en fikspunktiterasjon vil dette tilsvare $|g(x_i)-x_i|$, som også er et mål på hvor nær vi er fikspunktet $r = g(r)$.\n",
    "\n",
    "La oss sammenligne hvordan feilen avtar når vi utfører $N$ iterasjoner for de to metodene i forrige eksempel.\n",
    "<img src=\"2_fikspunktrate.png\" style=\"width: 100%\">\n",
    "Som en tilnærming til raten $S$ har vi tatt gjennomsnittsverdien av $e_{i+1}/e_{i}$ for $i = 0,...,N-1$ og i stedet brukt denne verdien.\n",
    "I plottet til venstre har vi plottet $|x_{k+1}-x_k|$ for hver iterasjon, og vi ser at disse følger kurven $S^k |x_1-x_0|$ veldig godt.\n",
    "\n",
    "Merk at dersom man har en feil $e_k$ som oppfyller den geometriske sammenhengen $e_{k} = S^k e_0$, kan vi ta logaritmen av begge sider og i stedet få $\\log_{10}(e_k) = k \\log_{10}(S) + \\log_{10}(e_0)$.\n",
    "Altså er logaritmen av feilen en lineær funksjon av $k$.\n",
    "Siden $S^k$ raskt blir veldig liten for $0 < S < 1$ og store verdier av $k$, er det ofte nyttig å skalere $y$-aksen i et feilplott logaritmisk istedenfor lineært:\n",
    "det vil si, når vi går én enhet langs $x$-aksen går vi fra $x=k$ til $x=k+1$, men langs $y$-aksen går vi i stedet fra $y = 10^{k}$ til $y = 10^{k+1}$.\n",
    "Dette er hva vi har gjort i plottet til høyre, hvor vi har brukt kommandoen `pyplot.semilogy()` istedenfor `pyplot.plot()`, og vi ser at feilene nå ligger mer eller mindre langs en rett linje."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fbb4b5-7012-43d5-8b39-d8809663a760",
   "metadata": {},
   "source": [
    "For fikspunktiterasjonen ovenfor avtar ikke feilene så raskt at de blir vanskelige å skille fra hverandre i normalt plott, men for Newtons metode vil vi se hvorfor det logaritmiske plottet er nyttig.\n",
    "<img src=\"2_newtonrate.png\" style=\"width: 100%\">\n",
    "Her har vi plottet feilene vi fikk med Newtons metode mot funksjoner med kvadratisk og lineært avtakende potenser, $10^{-k^2}|x_1-x_0|$ og $10^{-k}|x_1-x_0|$.\n",
    "Plottet til venstre er lineært skalert langs både $x$- og $y$-aksen, og vi ser at både feilen og funksjonene avtar raskt med $k$; det er også vakselig å skille funksjonene fra hverandre med det blotte øye for $k > 2$.\n",
    "\n",
    "I plottet til høyre, hvor $y$-aksen er logaritmisk skalert, ser vi lettere forskjell på funksjonene.\n",
    "I tillegg ser vi at feilen avtar raskere enn lineært, og dermed stemmer bedre overens med den kvadratiske potensen; vi kunne fått enda bedre overenstemmelse med kurven om vi hadde justert grunntallet $10^{-1}$ til raten vi får i akkurat dette tilfellet, slik vi gjorde med raten $S$ for fikspunktiterasjonen ovenfor.\n",
    "\n",
    "Her ser vi også at noen av punktene som dukker opp i det venstre plottet ikke synes i det høyre, nemlig for $k > 5$.\n",
    "Dette kan skje dersom feilene blir null, siden det ville tilsvart en uendelig negativ potens, $$ 0 = \\lim_\\limits{p\\to \\infty}10^{-p}, $$\n",
    "som det ikke gir mening å plotte.\n",
    "\n",
    "> **Merk:** Noen ganger har Newtons metode kun lineær konvergens, dette kan skje dersom $f'(r) = 0$ i roten $r$.\n",
    "Da finnes det måter å tilpasse Newtons metode på slik at konvergensen forblir kvadratisk, men vi går ikke inn på dette her."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb85080-65f5-4ed4-b4a6-f2e20b8bf7f1",
   "metadata": {},
   "source": [
    "> $\\impliedby$ [Newtons metode](2_lignlos_newton.ipynb) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e78799-0c12-4c9d-b5d5-4ee4264cb154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
